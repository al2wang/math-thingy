### Notes on Inferences for Regression
> Peer tutoring materials / Updated: 20 April 2022

- `Least-squares regression line`

  - `Population regression line` is calculated from **every value in the population**: $\mu _y=\beta_0+\beta_1x$

  - `Sample regression line` is calculated from **a particular sample**: $\hat y=b_0+b_1x$

  - `Sample slope's sampling distribution` shows **the pattern of variation in the sample slope** $b_1$

    - Simple random sample: $n$ observations out of $N$

    - Response value: $y$; explanatory value: $x$

    - Shape: approximately normal if the Normal condition is met, to wit $\forall x\in n(x)\to y\big|_{\text{normal}}$

    - Center: $\mu_{b_1}=\beta _1$, where $b_1$ is an **unbiased estimator** of $\beta_1$

    - 10% condition: $n<0.1N$

    - Variability/Standard deviation:$\ \sigma_{b_1}=\frac{\sigma}{\sigma _x\sqrt{n}} $, where $\sigma$ is **the SD of response variable** and that $\sigma_x$ is **the SD of explanatory variable**

- `Regression inference (LINER)`

  - Linear relationship between $x\sim y$
  - Observations are independent of each other (**check 10% condition when w/o replacement**)
  - Normal: $y-value$ varies according to a normal distribution as $x-value$ is fixed
  - Equal SD: $\sigma$ is always the same for all values of $x$
  - Random sample obtained

  - Useful templates:
    - Linear: The **scatter plot** of $y$ versus $x$ shows a linear form and there is no pattern in the residual plot.
    - Independent: Since the experiment is done randomly (and no objects are used twice), knowing the result of one observation should not help us predict the value of another observation.
    - Normal: There is no strong skewness or outliers in the histogram of **residuals**.
    - Equal SD: Similar amount of scatter about the **residual** = 0 line. However, the residual seems to vary more at (what $x$ values).
    - Random: The experiment objects are randomly assigned.

- `Estimating parameters`

  - `Standard error` shows **how far the sample slope typically varies from the true populational slope if we repeat the data production/random assignments many times**:  $SE_{b_1}=\frac{s}{s_x \sqrt{n-1}} $

  - Read out data from the `calculator table`:

    - `Constant Coef` is $b_0$: To wit to interpret the $y-intercept$, ... **on average**.
    - `x's Coef (Drop height)` is $b_1$: For an increase of 1 unit of the $x-value$, the **average** $y-value$ increases by ... unit.
    - `s value` is  $\sigma $: The actual  $y-value $ typically varies by about  $\sigma $ units from the predicted with the LSRL using $x=(explanatory\ variable\ name)$.
    - `SE value` is  $SE_{b_1}$: if we **repeat the data production/random assignments many times**, the sample slope typically varies by about $SE_{b_1}$ units from the true population slope for predicting $y-value$ from $x-value$.

- `Confidence interval of the slope`   $\text{t-interval}=b_1\pm t^{\*}\cdot SE_{b_1}; \text{df}(t^{\*})=n-2 $

  - Useful templates:
    - State: ...% CI for slope  $\beta $, where
      $\beta$
    is the true slope of the population regression line relating  $y-value$ to  $x-value$.
    - Plan: Linear regression t-interval for  $\beta$. LINER!
    - Do: CI formula, df, t*  $\to$ $CI\in(a,b)$
    - Conclude: We are CI% confident that the CI from ... to ... captures the true slope of the regression line relating  $y-value$ to  $x-value$.

- `Significant test for the slope`

  - The standardized test statistic  $t=\frac{b_1-\text{hypothesize slope}}{SE_{b_1}} $

  - Useful templates:

    - State: We want to test $H_0:\beta _1 =\text{hypothesized slope}\\ H_0:\beta _1 > \text{hypothesized slope}$
          where $\beta$ is the true slope of the population regression line relating $y-value$ to $x-value$ **at the confidence level $\alpha = 0.05$**.

    - Plan: Linear regression t-test for $\beta$. LINER!

    - Do: t-statistic formula, df $\to$  $t-statistic$;
     t-cdf  $\to p-value$

    - Conclude: Compare the  $p-value$ 
     to  $\alpha$.

      - Fail to reject $H_0$, there is no convincing evidence that $H_a$ is true.
      - Reject $H_0$, there is convincing evidence that $H_a$ is true.
